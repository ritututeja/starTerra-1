

<!DOCTYPE html>
<!--[if IE 8]><html class="no-js lt-ie9" lang="en" > <![endif]-->
<!--[if gt IE 8]><!--> <html class="no-js" lang="en" > <!--<![endif]-->
<head>
  <meta charset="utf-8">
  
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  
  <title>Pegasus Workflows with Application Containers &mdash; CyVerse Container Camp: Container Technology for Scientific Research 0.1.0 documentation</title>
  

  
  
  
  

  

  
  
    

  

  
    <link rel="stylesheet" href="../_static/css/theme.css" type="text/css" />
  <link rel="stylesheet" href="../_static/pygments.css" type="text/css" />
  <link rel="stylesheet" href="../_static/cyverse.css" type="text/css" />
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" />
    <link rel="next" title="Distributed Computing with Makeflow and Work Queue" href="containerscaling_dc.html" />
    <link rel="prev" title="OSG (Open Science Grid) Singularity Infrastructure" href="containerscaling_osg.html" /> 

  
  <script src="../_static/js/modernizr.min.js"></script>

</head>

<body class="wy-body-for-nav">

   
  <div class="wy-grid-for-nav">

    
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search">
          

          
            <a href="../index.html" class="icon icon-home"> CyVerse Container Camp: Container Technology for Scientific Research
          

          
          </a>

          
            
            
              <div class="version">
                0.1.0
              </div>
            
          

          
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="../search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>

          
        </div>

        <div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="main navigation">
          
            
            
              
            
            
              <p class="caption"><span class="caption-text">Container Camp Workshop</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../getting_started/main.html"><strong>Workshop Code of Conduct</strong></a></li>
<li class="toctree-l1"><a class="reference internal" href="../getting_started/installation.html"><strong>Pre-Workshop Setup</strong></a></li>
<li class="toctree-l1"><a class="reference internal" href="../getting_started/agenda.html"><strong>Agenda</strong></a></li>
<li class="toctree-l1"><a class="reference internal" href="../getting_started/about_cyverse.html"><strong>About CyVerse</strong></a></li>
</ul>
<p class="caption"><span class="caption-text">Workshop Topics</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../topics/train_docker.html"><strong>Training session in Docker</strong></a></li>
<li class="toctree-l1"><a class="reference internal" href="../topics/train_singularity.html"><strong>Training session in Singularity</strong></a></li>
<li class="toctree-l1"><a class="reference internal" href="../topics/train_containerscaling.html"><strong>Training session in scaling up your analysis using containers</strong></a></li>
<li class="toctree-l1"><a class="reference internal" href="../topics/train_biocontainers.html"><strong>Training session in Biocontainers</strong></a></li>
</ul>
<p class="caption"><span class="caption-text">Atmosphere</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../atmosphere/boot.html"><strong>Booting an Atmosphere computer instance for your use!</strong></a></li>
</ul>
<p class="caption"><span class="caption-text">Docker</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../docker/dockerintro.html"><strong>Introduction to Docker</strong></a></li>
<li class="toctree-l1"><a class="reference internal" href="../docker/dockeradvanced.html"><strong>Advanced Docker</strong></a></li>
</ul>
<p class="caption"><span class="caption-text">Singularity</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../singularity/singularityintro.html"><strong>Introduction to Singularity</strong></a></li>
<li class="toctree-l1"><a class="reference internal" href="../singularity/singularityadvanced.html"><strong>Advanced Singularity</strong></a></li>
</ul>
<p class="caption"><span class="caption-text">Deploying</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../deploying_apps/de_docker.html"><strong>Deploying apps in Discovery Environment</strong></a></li>
</ul>
<p class="caption"><span class="caption-text">Container Scaling</span></p>
<ul class="current">
<li class="toctree-l1"><a class="reference internal" href="containerscaling_osg.html"><strong>OSG (Open Science Grid) Singularity Infrastructure</strong></a></li>
<li class="toctree-l1 current"><a class="current reference internal" href="#"><strong>Pegasus Workflows with Application Containers</strong></a><ul>
<li class="toctree-l2"><a class="reference internal" href="#prerequisites">1. Prerequisites</a></li>
<li class="toctree-l2"><a class="reference internal" href="#what-are-scientific-workflows">2. What are Scientific Workflows?</a></li>
<li class="toctree-l2"><a class="reference internal" href="#pegasus-workflow-management-system">2. Pegasus Workflow Management System</a></li>
<li class="toctree-l2"><a class="reference internal" href="#exercise-1-without-containers">3. Exercise 1: Without Containers</a></li>
<li class="toctree-l2"><a class="reference internal" href="#exercise-2-with-containers">4. Exercise 2: With Containers</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="containerscaling_dc.html"><strong>Distributed Computing with Makeflow and Work Queue</strong></a></li>
</ul>
<p class="caption"><span class="caption-text">Biocontainers</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../biocontainer/biocontainers.html"><strong>Introduction to Biocontainers</strong></a></li>
<li class="toctree-l1"><a class="reference internal" href="../biocontainer/biocontainers_hpc.html"><strong>Biocontainers in HPC</strong></a></li>
</ul>
<p class="caption"><span class="caption-text">Useful Resources</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../useful_resources/usefulresources_docker.html"><strong>Docker related resources</strong></a></li>
<li class="toctree-l1"><a class="reference internal" href="../useful_resources/usefulresources_singularity.html"><strong>Singularity related resources</strong></a></li>
<li class="toctree-l1"><a class="reference internal" href="../useful_resources/usefulresources_other.html"><strong>Other resources</strong></a></li>
</ul>
<p class="caption"><span class="caption-text">Instructions and Reporting</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../instructions_reporting/instructors.html"><strong>For instructors!</strong></a></li>
<li class="toctree-l1"><a class="reference internal" href="../instructions_reporting/problems.html"><strong>Problems? Bugs? Questions?</strong></a></li>
</ul>

            
          
        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap">

      
      <nav class="wy-nav-top" aria-label="top navigation">
        
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="../index.html">CyVerse Container Camp: Container Technology for Scientific Research</a>
        
      </nav>


      <div class="wy-nav-content">
        
        <div class="rst-content">
        
          















<div role="navigation" aria-label="breadcrumbs navigation">

  <ul class="wy-breadcrumbs">
    
      <li><a href="../index.html">Docs</a> &raquo;</li>
        
      <li><strong>Pegasus Workflows with Application Containers</strong></li>
    
    
      <li class="wy-breadcrumbs-aside">
        
            
            <a href="../_sources/container_scaling/containerscaling_pegasus.rst.txt" rel="nofollow"> View page source</a>
          
        
      </li>
    
  </ul>

  
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
            
  <div class="section" id="pegasus-workflows-with-application-containers">
<h1><strong>Pegasus Workflows with Application Containers</strong><a class="headerlink" href="#pegasus-workflows-with-application-containers" title="Permalink to this headline">¶</a></h1>
<div class="admonition note">
<p class="first admonition-title">Note</p>
<p class="last">This section contains an overview of scientific workflows, Pegasus, and how containers fits into Pegasus workflows. We will not have time to thoroughly cover all aspects of Pegasus - for future reference please see the <a class="reference external" href="https://pegasus.isi.edu/documentation/">user guide</a> and <a class="reference external" href="https://pegasus.isi.edu/documentation/tutorial.php">self guided tutorial</a>.</p>
</div>
<div class="section" id="prerequisites">
<h2>1. Prerequisites<a class="headerlink" href="#prerequisites" title="Permalink to this headline">¶</a></h2>
<p>ssh will be used to connect to a remote job submit host. Please ensure you have a ssh client installed. The instructors will supply a slip of paper with username, password and hostname during the session.</p>
</div>
<div class="section" id="what-are-scientific-workflows">
<h2>2. What are Scientific Workflows?<a class="headerlink" href="#what-are-scientific-workflows" title="Permalink to this headline">¶</a></h2>
<p>Scientific workflows allow users to easily express multi-step computational tasks, for example retrieve data from an instrument or a database, reformat the data, and run an analysis. A scientific workflow describes the dependencies between the tasks and in most cases the workflow is described as a directed acyclic graph (DAG), where the nodes are tasks and the edges denote the task dependencies. A defining property for a scientific workflow is that it manages data flow. The tasks in a scientific workflow can be everything  from short serial tasks to very large parallel tasks (MPI for example) surrounded by a large number of small, serial tasks used for pre- and post-processing.</p>
<p><a class="reference internal" href="../_images/pegasus_diamond.png"><img alt="pegasus_diamond" src="../_images/pegasus_diamond.png" style="width: 300px; height: 300px;" /></a></p>
</div>
<div class="section" id="pegasus-workflow-management-system">
<h2>2. Pegasus Workflow Management System<a class="headerlink" href="#pegasus-workflow-management-system" title="Permalink to this headline">¶</a></h2>
<p>Pegasus WMS is a configurable system for mapping and executing abstract application workflows over a wide range of execution environments including a laptop, a campus cluster, a Grid, or a commercial or academic cloud. Today, Pegasus runs workflows on Amazon EC2, Google Compute Engine, Open Science Grid, XSEDE, and campus clusters. One workflow can run on a single system or across a heterogeneous set of resources.</p>
<p>Pegasus WMS bridges the scientific domain and the execution environment by automatically mapping high-level workflow descriptions onto distributed resources. It automatically locates the necessary input data and computational resources necessary for workflow execution. Pegasus enables scientists to construct workflows in abstract terms without worrying about the details of the underlying execution environment or the particulars of the low-level specifications required by the middleware (Condor, Globus, or Amazon EC2). Pegasus WMS also bridges the current cyberinfrastructure by effectively coordinating multiple distributed resources. The input to Pegasus is a description of the abstract workflow in XML format.</p>
<p>Pegasus has a number of features that contribute to its useability and effectiveness.</p>
<ul class="simple">
<li><strong>Portability / Reuse</strong>. User created workflows can easily be run in different environments without alteration. Pegasus currently runs workflows on top of Condor, Grid infrastrucutures such as Open Science Grid and TeraGrid, Amazon EC2, Nimbus, and many campus clusters. The same workflow can run on a single system or across a heterogeneous set of resources.</li>
<li><strong>Performance</strong>. The Pegasus mapper can reorder, group, and prioritize tasks in order to increase the overall workflow performance.</li>
<li><strong>Scalability</strong>. Pegasus can easily scale both the size of the workflow, and the resources that the workflow is distributed over. Pegasus runs workflows ranging from just a few computational tasks up to millions of tasks. The number of resources involved in executing a workflow can scale as needed without any impediments to performance.</li>
<li><strong>Provenance</strong>. By default, all jobs in Pegasus are launched via the kickstart process that captures runtime provenance of the job and helps in debugging. The provenance data is collected in a database, and the data can be summarised with tools such as pegasus-statistics, pegasus-plots, or directly with SQL queries.</li>
<li><strong>Data Management</strong>. Pegasus handles replica selection, data transfers and output registrations in data catalogs. These tasks are added to a workflow as auxilliary jobs by the Pegasus planner.</li>
<li><strong>Reliability</strong>. Jobs and data transfers are automatically retried in case of failures. Debugging tools such as pegasus-analyzer helps the user to debug the workflow in case of non-recoverable failures.</li>
<li><strong>Error Recovery</strong>.  When errors occur, Pegasus tries to recover when possible by retrying tasks, by retrying the entire workflow, by providing workflow-level checkpointing, by re-mapping portions of the workflow, by trying alternative data sources for staging data, and, when all else fails, by providing a rescue workflow containing a description of only the work that remains to be done. It cleans up storage as the workflow is executed so that data-intensive workflows have enough space to execute on storage-constrained resource. Pegasus keeps track of what has been done (provenance) including the locations of data used and produced, and which software was used with which parameters.</li>
</ul>
</div>
<div class="section" id="exercise-1-without-containers">
<h2>3. Exercise 1: Without Containers<a class="headerlink" href="#exercise-1-without-containers" title="Permalink to this headline">¶</a></h2>
<p>All of the example workflows described in the previous section can be generated with the pegasus-init command. For this tutorial we will be using the split workflow, which can be created like this:</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>$ pegasus-init split
Do you want to generate a tutorial workflow? <span class="o">(</span>y/n<span class="o">)</span> <span class="o">[</span>n<span class="o">]</span>: y
<span class="m">1</span>: Local Machine
<span class="m">2</span>: USC HPCC Cluster
<span class="m">3</span>: OSG from ISI submit node
<span class="m">4</span>: XSEDE, with Bosco
<span class="m">5</span>: Bluewaters, with Glite
What environment is tutorial to be setup <span class="k">for</span>? <span class="o">(</span><span class="m">1</span>-5<span class="o">)</span> <span class="o">[</span><span class="m">1</span><span class="o">]</span>: <span class="m">3</span>
<span class="m">1</span>: Process
<span class="m">2</span>: Pipeline
<span class="m">3</span>: Split
<span class="m">4</span>: Merge
<span class="m">5</span>: EPA <span class="o">(</span>requires R<span class="o">)</span>
What tutorial workflow <span class="k">do</span> you want? <span class="o">(</span><span class="m">1</span>-5<span class="o">)</span> <span class="o">[</span><span class="m">1</span><span class="o">]</span>: <span class="m">3</span>
Do you want to use Condor file transfers <span class="o">(</span>y/n<span class="o">)</span> <span class="o">[</span>y<span class="o">]</span>: y
Pegasus Tutorial setup <span class="k">for</span> example workflow - split <span class="k">for</span> execution on osg
</pre></div>
</div>
<p>The split workflow looks like this:</p>
<p><a class="reference internal" href="../_images/pegasus_split_wf.png"><img alt="pegasus_split_wf" src="../_images/pegasus_split_wf.png" style="width: 300px; height: 300px;" /></a></p>
<p>The input workflow description for Pegasus is called the DAX. It can be generated by running the <cite>generate_dax.sh</cite> script from the split directory, like this:</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>$ ./generate_dax.sh split.dax
Generated dax split.dax
</pre></div>
</div>
<p>This script will run a small Python program (<cite>daxgen.py</cite>) that generates a file with a .dax extension using the Pegasus Python API. Pegasus reads the DAX and generates an executable HTCondor workflow that is run on an execution site.</p>
<p>The <cite>pegasus-plan</cite> command is used to submit the workflow through Pegasus. The <cite>pegasus-plan</cite> command reads the input workflow (DAX file specified by –dax option), maps the abstract DAX to one or more execution sites, and submits the generated executable workflow to HTCondor. Among other things, the options to <cite>pegasus-plan</cite> tell Pegasus</p>
<ul class="simple">
<li>the workflow to run</li>
<li>where (what site) to run the workflow</li>
<li>the input directory where the inputs are placed</li>
<li>the output directory where the outputs are placed</li>
</ul>
<p>By default, the workflow is setup to run on the compute sites (i.e sites with handle other than “local”) defined in the <cite>sites.xml</cite> file. In our example, the workflow will run on a site named “condorpool” in the <cite>sites.xml</cite> file.</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>$ ./plan_dax.sh split.dax

-----------------------------------------------------------------------
File <span class="k">for</span> submitting this DAG to HTCondor       : split-0.dag.condor.sub
Log of DAGMan debugging messages               : split-0.dag.dagman.out
Log of HTCondor library output                 : split-0.dag.lib.out
Log of HTCondor library error messages         : split-0.dag.lib.err
Log of the life of condor_dagman itself        : split-0.dag.dagman.log
-----------------------------------------------------------------------
Submitting to condor split-0.dag.condor.sub
Submitting job<span class="o">(</span>s<span class="o">)</span>.
<span class="m">1</span> job<span class="o">(</span>s<span class="o">)</span> submitted to cluster <span class="m">920589</span>.

Your workflow has been started and is running in the base directory:

  /split/submit/pegtrain50/pegasus/split/run0001

*** To monitor the workflow you can run ***

  pegasus-status -l /split/submit/pegtrain50/pegasus/split/run0001

*** To remove your workflow run ***

  pegasus-remove /split/submit/pegtrain50/pegasus/split/run0001
</pre></div>
</div>
<p>This is what the split workflow looks like after Pegasus has finished planning the DAX:</p>
<p><a class="reference internal" href="../_images/pegasus_split_dag.png"><img alt="pegasus_split_dag" src="../_images/pegasus_split_dag.png" style="width: 750px; height: 700px;" /></a></p>
<p>You can monitor the workflow with the <cite>pegasus-status</cite> command provided in the output of the <cite>plan_dax.sh</cite> command:</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>pegasus-status -l /split/submit/pegtrain50/pegasus/split/run0001
</pre></div>
</div>
<p>More details on how to run basic workflow can be found in the <a class="reference external" href="https://pegasus.isi.edu/documentation/tutorial.php">Pegasus Tutorial</a></p>
</div>
<div class="section" id="exercise-2-with-containers">
<h2>4. Exercise 2: With Containers<a class="headerlink" href="#exercise-2-with-containers" title="Permalink to this headline">¶</a></h2>
<p>Now when we have a basic understanding of what a Pegasus workflow looks like, let’s use containers to run some real science codes. This example is based on IPAC’s <a class="reference external" href="http://montage.ipac.caltech.edu/">Montage</a> toolkit, which is used to process and create astronomical image mosaics of from telescope images datasets. The workflow has a few software dependencies: Montage obviously, but also Python modules like AstroPy. These could be installed on the cluster you want to run the workflow on, but using containers makes it even easier!</p>
<p>Not only will we make the compute jobs run inside containers, but also the data find step needed to construct the workflow. IPAC provides services to list the images available for a given location in the sky (for example, see the documentation for <a class="reference external" href="http://montage.ipac.caltech.edu/docs/mArchiveList.html">mArchiveList</a>). For this querying we will use the same container as the jobs will be using. To get started, clone the Montage workflow from GitHub, and run the data find step:</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>$ <span class="nb">cd</span> ~
$ git clone https://github.com/pegasus-isi/montage-workflow-v2.git
$ <span class="nb">cd</span> montage-workflow-v2
$ singularity <span class="nb">exec</span> <span class="se">\</span>
              --bind <span class="nv">$PWD</span>:/srv --pwd /srv <span class="se">\</span>
              shub://pegasus-isi/montage-workflow-v2 <span class="se">\</span>
              /srv/montage-workflow.py <span class="se">\</span>
                  --tc-target container <span class="se">\</span>
                  --center <span class="s2">&quot;275.196290 -16.171530&quot;</span> <span class="se">\</span>
                  --degrees <span class="m">0</span>.2 <span class="se">\</span>
                  --band 2mass:j:green <span class="se">\</span>
                  --band 2mass:h:blue <span class="se">\</span>
                  --band 2mass:k:red
</pre></div>
</div>
<p>The three different <cite>band</cite> arguments specify different bands that we want to find images for, and map to <cite>blue</cite>, <cite>green</cite>, and <cite>red</cite> in to the final image. The output of the command should show a few images found for each band:</p>
<div class="highlight-none notranslate"><div class="highlight"><pre><span></span>Progress |===================================| 100.0%

Adding band 1 (2mass j -&gt; green)
Running sub command: mArchiveList 2mass j &quot;275.196290 -16.171530&quot; 0.284 0.284 data/1-images.tbl
[struct stat=&quot;OK&quot;, module=&quot;mArchiveList&quot;, count=8]
Running sub command: cd data &amp;&amp; mDAGTbls 1-images.tbl region-oversized.hdr 1-raw.tbl 1-projected.tbl 1-corrected.tbl
[struct stat=&quot;OK&quot;, count=&quot;8&quot;, total=&quot;8&quot;]
Running sub command: cd data &amp;&amp; mOverlaps 1-raw.tbl 1-diffs.tbl
[struct stat=&quot;OK&quot;, module=&quot;mOverlaps&quot;, count=13]

Adding band 2 (2mass h -&gt; blue)
Running sub command: mArchiveList 2mass h &quot;275.196290 -16.171530&quot; 0.284 0.284 data/2-images.tbl
[struct stat=&quot;OK&quot;, module=&quot;mArchiveList&quot;, count=8]
Running sub command: cd data &amp;&amp; mDAGTbls 2-images.tbl region-oversized.hdr 2-raw.tbl 2-projected.tbl 2-corrected.tbl
[struct stat=&quot;OK&quot;, count=&quot;8&quot;, total=&quot;8&quot;]
Running sub command: cd data &amp;&amp; mOverlaps 2-raw.tbl 2-diffs.tbl
[struct stat=&quot;OK&quot;, module=&quot;mOverlaps&quot;, count=13]

Adding band 3 (2mass k -&gt; red)
Running sub command: mArchiveList 2mass k &quot;275.196290 -16.171530&quot; 0.284 0.284 data/3-images.tbl
[struct stat=&quot;OK&quot;, module=&quot;mArchiveList&quot;, count=8]
Running sub command: cd data &amp;&amp; mDAGTbls 3-images.tbl region-oversized.hdr 3-raw.tbl 3-projected.tbl 3-corrected.tbl
[struct stat=&quot;OK&quot;, count=&quot;8&quot;, total=&quot;8&quot;]
Running sub command: cd data &amp;&amp; mOverlaps 3-raw.tbl 3-diffs.tbl
[struct stat=&quot;OK&quot;, module=&quot;mOverlaps&quot;, count=13]
</pre></div>
</div>
<p>The <cite>data/</cite> directory contains the imformation about the input images, the generated workflow (<cite>data/montage.dax</cite>) and the transformation catalog (<cite>data/tc.txt</cite>) which tells Pegasus where software is available. A job in the <cite>data/montage.dax</cite> file might look like:</p>
<div class="highlight-xml notranslate"><div class="highlight"><pre><span></span><span class="nt">&lt;job</span> <span class="na">id=</span><span class="s">&quot;ID0000001&quot;</span> <span class="na">name=</span><span class="s">&quot;mProject&quot;</span><span class="nt">&gt;</span>
    <span class="nt">&lt;argument&gt;</span>-X <span class="nt">&lt;file</span> <span class="na">name=</span><span class="s">&quot;2mass-atlas-990502s-j1420198.fits&quot;</span><span class="nt">/&gt;</span> <span class="nt">&lt;file</span> <span class="na">name=</span><span class="s">&quot;p2mass-atlas-990502s-j1420198.fits&quot;</span><span class="nt">/&gt;</span> <span class="nt">&lt;file</span> <span class="na">name=</span><span class="s">&quot;region-oversized.hdr&quot;</span><span class="nt">/&gt;&lt;/argument&gt;</span>
    <span class="nt">&lt;uses</span> <span class="na">name=</span><span class="s">&quot;region-oversized.hdr&quot;</span> <span class="na">link=</span><span class="s">&quot;input&quot;</span><span class="nt">/&gt;</span>
    <span class="nt">&lt;uses</span> <span class="na">name=</span><span class="s">&quot;2mass-atlas-990502s-j1420198.fits&quot;</span> <span class="na">link=</span><span class="s">&quot;input&quot;</span><span class="nt">/&gt;</span>
    <span class="nt">&lt;uses</span> <span class="na">name=</span><span class="s">&quot;p2mass-atlas-990502s-j1420198.fits&quot;</span> <span class="na">link=</span><span class="s">&quot;output&quot;</span> <span class="na">transfer=</span><span class="s">&quot;false&quot;</span><span class="nt">/&gt;</span>
    <span class="nt">&lt;uses</span> <span class="na">name=</span><span class="s">&quot;p2mass-atlas-990502s-j1420198_area.fits&quot;</span> <span class="na">link=</span><span class="s">&quot;output&quot;</span> <span class="na">transfer=</span><span class="s">&quot;false&quot;</span><span class="nt">/&gt;</span>
<span class="nt">&lt;/job&gt;</span>
</pre></div>
</div>
<p><cite>data/tc.txt</cite> has the specification on how <cite>mProject</cite> can be executed:</p>
<div class="highlight-none notranslate"><div class="highlight"><pre><span></span>tr mProject {
  site condor_pool {
    type &quot;INSTALLED&quot;
    container &quot;montage&quot;
    pfn &quot;file:///opt/Montage/bin/mProject&quot;
    profile pegasus &quot;clusters.size&quot; &quot;3&quot;
  }
}
</pre></div>
</div>
<p>Note the <cite>container “montage”</cite> part - this is a reference to the top of the file which has:</p>
<div class="highlight-none notranslate"><div class="highlight"><pre><span></span>cont montage {
   type &quot;singularity&quot;
   image &quot;shub://pegasus-isi/montage-workflow-v2&quot;
   profile env &quot;MONTAGE_HOME&quot; &quot;/opt/Montage&quot;
}
</pre></div>
</div>
<p>Which is the same container we used for the data find step. Note that container images is just like any other piece of data to Pegasus. In this case, the image will be downloaded <strong>once</strong> from the Singularity Hub, and then shipped around to the jobs with the same mechanism as any other data in the workflow.</p>
<p>There is currently a small issue by running the data find step inside a container - the paths for the files are based on paths in the container which are different from what Pegasus expects on the submit host. The following command adjusts those paths:</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>$ perl -p -i -e <span class="s2">&quot;s;/srv/data;</span><span class="nv">$PWD</span><span class="s2">/data;g&quot;</span> data/rc.txt
</pre></div>
</div>
<p>Now we are are ready to plan and submit the workflow:</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>$ pegasus-plan <span class="se">\</span>
        --dir work <span class="se">\</span>
        --relative-dir <span class="sb">`</span>date +<span class="s1">&#39;%s&#39;</span><span class="sb">`</span> <span class="se">\</span>
        --dax data/montage.dax <span class="se">\</span>
        --sites condor_pool <span class="se">\</span>
        --output-site <span class="nb">local</span> <span class="se">\</span>
        --submit
</pre></div>
</div>
<p>The workflow will looks something like this:</p>
<p><a class="reference internal" href="../_images/pegasus_montage_dax.png"><img alt="pegasus_montage_dax" src="../_images/pegasus_montage_dax.png" style="width: 750px; height: 700px;" /></a></p>
<p>The first level reprojects the input images to a common projection. The images are then fitted together. A background correction is applied so that the the final image will be seamless. The last step is to take the 3 different color bands, and add them together into a final output image:</p>
<p><a class="reference internal" href="../_images/pegasus_montage_result.png"><img alt="pegasus_montage_result" src="../_images/pegasus_montage_result.png" style="width: 750px; height: 700px;" /></a></p>
<p>To see how Pegasus handled the container in this case, let’s look at some plumming for one of the <cite>mProject</cite> job. The HTCondor submit file can be seen with:</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>$ cat <span class="sb">`</span>find . -name mProject_ID0000002.sub<span class="sb">`</span>
</pre></div>
</div>
<p>Look at the <cite>transfer_input_files</cite> attribute line, and specifically for the <cite>montage.simg</cite> file. It is transferred together with all the other inputs for the job:</p>
<div class="highlight-none notranslate"><div class="highlight"><pre><span></span>transfer_input_files = region-oversized.hdr,2mass-atlas-990502s-j1350092.fits,montage.simg,/opt/training/pegasus-4.8.2dev/share/pegasus/sh/pegasus-lite-common.sh,/scitech/home/pegtrain99/montage-workflow-v2/work/1520295762/pegasus-worker-4.8.2dev-x86_64_rhel_7.tar.gz
</pre></div>
</div>
<p>Looking at the corresponding <cite>.sh</cite> file we can see how Pegasus executed the container:</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>$ cat <span class="sb">`</span>find . -name mProject_ID0000002.sh<span class="sb">`</span>
...
singularity <span class="nb">exec</span> --pwd /srv --scratch /var/tmp --scratch /tmp --home <span class="nv">$PWD</span>:/srv montage.simg ./mProject_ID0000002-cont.sh
...
</pre></div>
</div>
<p>The <cite>./mProject_ID0000002-cont.sh</cite> is a script generated at runtime, containing the execution of the user codes.</p>
</div>
</div>


           </div>
           
          </div>
          <footer>
  
    <div class="rst-footer-buttons" role="navigation" aria-label="footer navigation">
      
        <a href="containerscaling_dc.html" class="btn btn-neutral float-right" title="Distributed Computing with Makeflow and Work Queue" accesskey="n" rel="next">Next <span class="fa fa-arrow-circle-right"></span></a>
      
      
        <a href="containerscaling_osg.html" class="btn btn-neutral" title="OSG (Open Science Grid) Singularity Infrastructure" accesskey="p" rel="prev"><span class="fa fa-arrow-circle-left"></span> Previous</a>
      
    </div>
  

  <hr/>

  <div role="contentinfo">
    <p>
        &copy; Copyright 2018, CyVerse.

    </p>
  </div>
  Built with <a href="http://sphinx-doc.org/">Sphinx</a> using a <a href="https://github.com/rtfd/sphinx_rtd_theme">theme</a> provided by <a href="https://readthedocs.org">Read the Docs</a>. 

</footer>

        </div>
      </div>

    </section>

  </div>
  


  

    <script type="text/javascript">
        var DOCUMENTATION_OPTIONS = {
            URL_ROOT:'../',
            VERSION:'0.1.0',
            LANGUAGE:'None',
            COLLAPSE_INDEX:false,
            FILE_SUFFIX:'.html',
            HAS_SOURCE:  true,
            SOURCELINK_SUFFIX: '.txt'
        };
    </script>
      <script type="text/javascript" src="../_static/jquery.js"></script>
      <script type="text/javascript" src="../_static/underscore.js"></script>
      <script type="text/javascript" src="../_static/doctools.js"></script>
      <script type="text/javascript" src="../_static/jquery.tablesorter.min.js"></script>
      <script type="text/javascript" src="../_static/cyverse.js"></script>

  

  
  
    <script type="text/javascript" src="../_static/js/theme.js"></script>
  

  <script type="text/javascript">
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script> 

</body>
</html>